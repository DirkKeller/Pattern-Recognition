{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "\n",
    "from labml import lab, tracker, experiment, monit\n",
    "from labml.configs import BaseConfigs, option\n",
    "from labml_helpers.device import DeviceConfigs\n",
    "from noise import DenoiseDiffusion\n",
    "from unet import UNet\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Settings for restoring/creating experiment\n",
    "\n",
    "    # LOAD_CHECKPOINT = True\n",
    "    LOAD_CHECKPOINT = False\n",
    "    MY_UUID = 'AbeSaveTesting' \n",
    "\n",
    "    # Create experiment\n",
    "    experiment.create(\n",
    "        name='diffuse', \n",
    "        writers={'screen', 'labml'},\n",
    "        uuid=MY_UUID,\n",
    "    )\n",
    "\n",
    "    if not LOAD_CHECKPOINT:\n",
    "        # Create configurations\n",
    "        configs = Configs()\n",
    "        print(f'Status: Device is using GPU: {torch.cuda.is_available()}')\n",
    "\n",
    "        # for exp in ['recurrent', 'residual']:\n",
    "        for exp in ['residual']:\n",
    "            configs.convolutional_block = exp\n",
    "\n",
    "            # Set configurations. You can override the defaults by passing the values in the dictionary.\n",
    "            experiment.configs(configs, {\n",
    "                'dataset': 'MNIST',  # 'CIFAR10', 'CelebA' 'MNIST'\n",
    "                'image_channels': 1,  # 3, 3, 1\n",
    "                'epochs': 2,  # 100, 100, 5\n",
    "            })\n",
    "\n",
    "            # Initialize\n",
    "            configs.init()\n",
    "\n",
    "            # Set models for saving and loading\n",
    "            experiment.add_pytorch_models({'eps_model': configs.eps_model})\n",
    "    elif LOAD_CHECKPOINT:\n",
    "\n",
    "        # Load the experiment from \n",
    "        experiment.load(checkpoint=MY_UUID) # Note: passing 'run_uuid=UUID' will try restoring from a checkpoint within current run (or so I think)\n",
    "\n",
    "\n",
    "\n",
    "    # Start and run the training loop\n",
    "    with experiment.start():\n",
    "        configs.run()\n",
    "\n",
    "\n",
    "\n",
    "class Configs(BaseConfigs):\n",
    "    \"\"\"\n",
    "    Class for holding configuration parameters for training a DDPM model.\n",
    "\n",
    "    Attributes:\n",
    "        device (torch.device):           Device on which to run the model.\n",
    "        eps_model (UNet):                U-Net model for the function `epsilon_theta`.\n",
    "        diffusion (DenoiseDiffusion):    DDPM algorithm.\n",
    "        image_channels (int):            Number of channels in the image (e.g. 3 for RGB).\n",
    "        image_size (int):                Size of the image.\n",
    "        n_channels (int):                Number of channels in the initial feature map.\n",
    "        channel_multipliers (List[int]): Number of channels at each resolution.\n",
    "        is_attention (List[bool]):       Indicates whether to use attention at each resolution.\n",
    "        convolutional_block (str):       Type of the convolutional block used\n",
    "        schedule_name (str):             Function of the noise schedule\n",
    "        n_steps (int):                   Number of time steps.\n",
    "        batch_size (int):                Batch size.\n",
    "        n_samples (int):                 Number of samples to generate.\n",
    "        learning_rate (float):           Learning rate.\n",
    "        epochs (int):                    Number of training epochs.\n",
    "        dataset (torch.utils.data.Dataset):         Dataset to be used for training.\n",
    "        data_loader (torch.utils.data.DataLoader):  DataLoader for loading the data for training.\n",
    "        optimizer (torch.optim.Adam):               Optimizer for the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Device to train the model on.\n",
    "    # [`DeviceConfigs`](https://docs.labml.ai/api/helpers.html#labml_helpers.device.DeviceConfigs)\n",
    "    #  picks up an available CUDA device or defaults to CPU.\n",
    "    device: torch.device = DeviceConfigs()\n",
    "    # Retrieve model information\n",
    "    show = True\n",
    "\n",
    "    # U-Net model for $\\textcolor{lightgreen}{\\epsilon_\\theta}(x_t, t)$\n",
    "    eps_model: UNet\n",
    "    # [DDPM algorithm](index.html)\n",
    "    diffusion: DenoiseDiffusion\n",
    "\n",
    "    # Number of channels in the image. $3$ for RGB.\n",
    "    image_channels: int = 3\n",
    "    # Image size\n",
    "    image_size: int = 32\n",
    "    # Number of channels in the initial feature map\n",
    "    n_channels: int = 64  # 64 (Default: Ho et al.; Limit is VRAM)\n",
    "    # The list of channel numbers at each resolution.\n",
    "    # The number of channels is `channel_multipliers[i] * n_channels`\n",
    "    channel_multipliers: List[int] = [1, 2, 2, 4]\n",
    "    # The list of booleans that indicate whether to use attention at each resolution\n",
    "    is_attention: List[int] = [False, False, False, True]\n",
    "    # Convolutional block type used in the UNet blocks. Possible options are 'residual' and 'recurrent'.\n",
    "    convolutional_block = 'residual'\n",
    "\n",
    "    # Defines the noise schedule. Possible options are 'linear' and 'cosine'.\n",
    "    schedule_name: str = 'linear'\n",
    "    # Number of time steps $T$ (with $T$ = 1_000 from Ho et al).\n",
    "    n_steps: int = 1000  # 1000 (Default: Ho et al.)\n",
    "\n",
    "    # Batch size\n",
    "    batch_size: int = 64  # 64 (Default: Ho et al.; Limit is VRAM)\n",
    "    # Number of samples to generate\n",
    "    n_samples: int = 16\n",
    "    # Learning rate\n",
    "    learning_rate: float = 2e-5\n",
    "    # Number of training epochs\n",
    "    epochs: int = 1000\n",
    "\n",
    "    # Dataset\n",
    "    dataset: torch.utils.data.Dataset\n",
    "    # Dataloader\n",
    "    data_loader: torch.utils.data.DataLoader\n",
    "\n",
    "    # Adam optimizer\n",
    "    optimizer: torch.optim.Adam\n",
    "\n",
    "    def init(self):\n",
    "        \"\"\"\n",
    "        Initialize the model, dataset, and optimizer objects.\n",
    "        \"\"\"\n",
    "\n",
    "        # Create $\\textcolor{lightgreen}{\\epsilon_\\theta}(x_t, t)$ model\n",
    "        self.eps_model = UNet(\n",
    "            image_channels=self.image_channels,\n",
    "            n_channels=self.n_channels,\n",
    "            ch_mults=self.channel_multipliers,\n",
    "            is_attn=self.is_attention,\n",
    "            conv_block=self.convolutional_block\n",
    "        ).to(self.device)\n",
    "\n",
    "        # Create [DDPM class](index.html)\n",
    "        self.diffusion = DenoiseDiffusion(\n",
    "            eps_model=self.eps_model,\n",
    "            n_steps=self.n_steps,\n",
    "            schedule_name=self.schedule_name,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "        # Show the number of params used by the model\n",
    "        if self.show:\n",
    "            pytorch_total_params = sum(p.numel() for p in self.eps_model.parameters())\n",
    "            print(f'The total number of parameters are: {pytorch_total_params}')\n",
    "\n",
    "        # Create dataloader\n",
    "        self.data_loader = torch.utils.data.DataLoader(self.dataset, self.batch_size, shuffle=True, pin_memory=True)\n",
    "        # Create optimizer\n",
    "        self.optimizer = torch.optim.Adam(self.eps_model.parameters(), lr=self.learning_rate)\n",
    "\n",
    "        # Image logging\n",
    "        tracker.set_image(\"sample\", True)\n",
    "\n",
    "    def sample(self) -> None:\n",
    "        \"\"\"\n",
    "        Generate samples from a trained Denoising Diffusion Probabilistic Model (DDPM).\n",
    "        \"\"\"\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Sample from the noise distribution at the final time step: x_T ~ p(x_T) = N(x_T; 0, I)\n",
    "            x = torch.randn([self.n_samples, self.image_channels, self.image_size, self.image_size],\n",
    "                            device=self.device)\n",
    "\n",
    "            # Remove noise at each time step in reverse order (so remove noise for T steps)\n",
    "            for t_ in monit.iterate('Sample', self.n_steps):\n",
    "                # Get current time step\n",
    "                t = self.n_steps - t_ - 1\n",
    "                # Sample from the noise distribution at the current time step: x_{t-1} ~ p_theta(x_{t-1}|x_t)\n",
    "                x = self.diffusion.p_sample(x, x.new_full((self.n_samples,), t, dtype=torch.long))\n",
    "\n",
    "            # Log the final denoised samples\n",
    "            tracker.save('sample', x)\n",
    "\n",
    "    def train(self) -> None:\n",
    "        \"\"\"\n",
    "        Train a Denoising Diffusion Probabilistic Model (DDPM) with the set dataloader.\n",
    "        \"\"\"\n",
    "\n",
    "        # Iterate through the dataset\n",
    "        for data in monit.iterate('Train', self.data_loader):\n",
    "            # Increment global step\n",
    "            tracker.add_global_step()\n",
    "            # Move data to device\n",
    "            data = data.to(self.device)\n",
    "\n",
    "            # Make the gradients zero\n",
    "            self.optimizer.zero_grad()\n",
    "            # Calculate loss\n",
    "            loss = self.diffusion.loss(data)\n",
    "            # Compute gradients\n",
    "            loss.backward()\n",
    "            # Take an optimization step\n",
    "            self.optimizer.step()\n",
    "            # Track the loss\n",
    "            tracker.save('loss', loss)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        ### Training loop\n",
    "        \"\"\"\n",
    "        for _ in monit.loop(self.epochs):\n",
    "            # Train the model\n",
    "            self.train()\n",
    "            # Sample some images\n",
    "            self.sample()\n",
    "            # New line in the console\n",
    "            tracker.new_line()\n",
    "            # Save the model\n",
    "            experiment.save_checkpoint()\n",
    "\n",
    "\n",
    "class MNISTDataset(torchvision.datasets.MNIST):\n",
    "    \"\"\"\n",
    "    ### MNIST dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_size):\n",
    "        transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(image_size),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        super().__init__(str(lab.get_data_path()), train=True, download=True, transform=transform)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return super().__getitem__(item)[0]\n",
    "\n",
    "\n",
    "@option(Configs.dataset, 'MNIST')\n",
    "def mnist_dataset(c: Configs):\n",
    "    \"\"\"\n",
    "    Create MNIST dataset\n",
    "    \"\"\"\n",
    "    return MNISTDataset(c.image_size)\n",
    "\n",
    "\n",
    "class CIFAR10Dataset(torchvision.datasets.CIFAR10):\n",
    "    \"\"\"\n",
    "    ### MNIST dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image_size):\n",
    "        transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.Resize(image_size),\n",
    "            torchvision.transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        super().__init__(str(lab.get_data_path()), train=True, download=True, transform=transform)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return super().__getitem__(item)[0]\n",
    "\n",
    "\n",
    "@option(Configs.dataset, 'CIFAR10')\n",
    "def mnist_dataset(c: Configs):\n",
    "    \"\"\"\n",
    "    Create CIFAR10 dataset\n",
    "    \"\"\"\n",
    "    return CIFAR10Dataset(c.image_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b0d658703a4726980f8e5534331c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<pre  style=\"overflow-x: scroll;\"><span style=\"color: #C5C1B4\"></span>\\n<span style=\"color: #C5C1B…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Device is using GPU: False\n",
      "The total number of parameters are: 167775681\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
